{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import cpu_count\n",
    "import psutil\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path(\"/mnt/home/dchhantyal/3d-cnn-classification\")\n",
    "sys.path.append(str(PROJECT_ROOT / \"preperation\" / \"python\"))\n",
    "\n",
    "# Import parallel extraction modules\n",
    "from parallel_nucleus_extractor import (\n",
    "    ParallelNucleusExtractor, \n",
    "    ParallelConfig, \n",
    "    create_optimized_config,\n",
    "    ProgressTracker\n",
    ")\n",
    "\n",
    "print(f\"üñ•Ô∏è  System Information:\")\n",
    "print(f\"   ‚Ä¢ CPU cores: {cpu_count()}\")\n",
    "print(f\"   ‚Ä¢ Available memory: {psutil.virtual_memory().available / (1024**3):.1f} GB\")\n",
    "print(f\"   ‚Ä¢ Total memory: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "print(f\"   ‚Ä¢ CPU usage: {psutil.cpu_percent(interval=1):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c2b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"/mnt/home/dchhantyal/3d-cnn-classification\"\n",
    "DATASET_NAME = \"230212_stack6\"  # Change this to your target dataset\n",
    "\n",
    "# Auto-optimize configuration based on system resources\n",
    "available_memory = psutil.virtual_memory().available / (1024**3)  # GB\n",
    "estimated_dataset_size = 500  # Adjust based on your dataset\n",
    "\n",
    "print(f\"üîß Creating optimized configuration...\")\n",
    "config = create_optimized_config(\n",
    "    dataset_size=estimated_dataset_size,\n",
    "    available_memory_gb=available_memory * 0.8  # Use 80% of available memory\n",
    ")\n",
    "\n",
    "# You can also create a custom configuration\n",
    "# custom_config = ParallelConfig(\n",
    "#     max_workers_batch=4,\n",
    "#     max_workers_frames=8, \n",
    "#     max_workers_io=16,\n",
    "#     chunk_size=50,\n",
    "#     enable_detailed_logging=True,\n",
    "#     save_intermediate_results=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parallel extractor\n",
    "print(f\"üöÄ Initializing Parallel Nucleus Extractor...\")\n",
    "extractor = ParallelNucleusExtractor(DATA_PATH, config)\n",
    "\n",
    "# Load the dataset\n",
    "print(f\"üìä Loading dataset: {DATASET_NAME}\")\n",
    "success = extractor.load_dataset(DATASET_NAME)\n",
    "\n",
    "if success:\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    \n",
    "    # Display dataset statistics\n",
    "    df = extractor.metadata[\"classes\"]\n",
    "    print(f\"\\nüìà Dataset Statistics:\")\n",
    "    print(f\"   ‚Ä¢ Total nuclei: {len(df)}\")\n",
    "    print(f\"   ‚Ä¢ Mitotic events: {df['mitotic'].sum()}\")\n",
    "    print(f\"   ‚Ä¢ Death events: {df['death'].sum()}\")\n",
    "    print(f\"   ‚Ä¢ Both events: {((df['mitotic'] == 1) & (df['death'] == 1)).sum()}\")\n",
    "    print(f\"   ‚Ä¢ Normal nuclei: {((df['mitotic'] == 0) & (df['death'] == 0)).sum()}\")\n",
    "    \n",
    "    # Frame distribution\n",
    "    print(f\"\\nüé¨ Frame Distribution:\")\n",
    "    frame_counts = df['frame'].value_counts().sort_index()\n",
    "    print(f\"   ‚Ä¢ Frame range: {frame_counts.index.min()} - {frame_counts.index.max()}\")\n",
    "    print(f\"   ‚Ä¢ Avg nuclei per frame: {frame_counts.mean():.1f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Failed to load dataset: {DATASET_NAME}\")\n",
    "    print(\"Please check the dataset path and name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f739ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single nucleus extraction (performance comparison)\n",
    "if success:\n",
    "    # Get a sample nucleus for testing\n",
    "    sample_nucleus = df.iloc[0]\n",
    "    nucleus_id = int(sample_nucleus['nucleus_id'])\n",
    "    event_frame = int(sample_nucleus['frame'])\n",
    "    \n",
    "    print(f\"üß™ Testing single nucleus extraction...\")\n",
    "    print(f\"   ‚Ä¢ Nucleus ID: {nucleus_id}\")\n",
    "    print(f\"   ‚Ä¢ Event frame: {event_frame}\")\n",
    "    print(f\"   ‚Ä¢ Classification: Mitotic={sample_nucleus['mitotic']}, Death={sample_nucleus['death']}\")\n",
    "    \n",
    "    # Time the parallel extraction\n",
    "    start_time = time.time()\n",
    "    result = extractor.extract_nucleus_time_series_parallel(nucleus_id, event_frame)\n",
    "    parallel_time = time.time() - start_time\n",
    "    \n",
    "    if result and result['extraction_success']:\n",
    "        print(f\"‚úÖ Parallel extraction successful!\")\n",
    "        print(f\"   ‚Ä¢ Processing time: {parallel_time:.2f} seconds\")\n",
    "        print(f\"   ‚Ä¢ Successful frames: {result['successful_frames']}/{result['total_frames']}\")\n",
    "        print(f\"   ‚Ä¢ Extracted frames: {list(result['time_series'].keys())}\")\n",
    "        \n",
    "        # Display frame-level results\n",
    "        for frame_label, frame_data in result['time_series'].items():\n",
    "            if frame_data.get('success', False):\n",
    "                bbox = frame_data['bbox']\n",
    "                print(f\"     {frame_label}: ‚úÖ Cropped to {bbox}\")\n",
    "            else:\n",
    "                print(f\"     {frame_label}: ‚ùå {frame_data.get('error', 'Unknown error')}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Parallel extraction failed\")\n",
    "        \n",
    "    # Memory usage check\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    print(f\"\\nüíæ Memory Usage:\")\n",
    "    print(f\"   ‚Ä¢ Available: {memory_info.available / (1024**3):.1f} GB\")\n",
    "    print(f\"   ‚Ä¢ Used: {memory_info.percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc904f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small batch test (10 nuclei)\n",
    "if success:\n",
    "    print(f\"üß™ Testing small batch extraction (10 nuclei)...\")\n",
    "    \n",
    "    # Test with a small batch first\n",
    "    start_time = time.time()\n",
    "    successful = extractor.batch_extract_nuclei_parallel(\n",
    "        max_samples=10,\n",
    "        event_types=[\"death\", \"mitotic\"],  # Focus on interesting events\n",
    "        dataset_name=DATASET_NAME\n",
    "    )\n",
    "    batch_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nüìä Small Batch Results:\")\n",
    "    print(f\"   ‚Ä¢ Processing time: {batch_time:.2f} seconds\")\n",
    "    print(f\"   ‚Ä¢ Successful extractions: {successful}\")\n",
    "    print(f\"   ‚Ä¢ Average time per nucleus: {batch_time/10:.2f} seconds\")\n",
    "    print(f\"   ‚Ä¢ Estimated rate: {10/batch_time:.2f} nuclei/second\")\n",
    "    \n",
    "    # Memory usage after batch\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    print(f\"   ‚Ä¢ Memory usage: {memory_info.percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full batch extraction by event type\n",
    "if success:\n",
    "    print(f\"üöÄ Running full parallel batch extraction...\")\n",
    "    \n",
    "    # Extract different event types separately for better organization\n",
    "    event_configs = [\n",
    "        {\"types\": [\"death\"], \"max_samples\": 100, \"description\": \"Death Events\"},\n",
    "        {\"types\": [\"mitotic\"], \"max_samples\": 100, \"description\": \"Mitotic Events\"},\n",
    "        {\"types\": [\"normal\"], \"max_samples\": 50, \"description\": \"Normal Nuclei (Controls)\"},\n",
    "    ]\n",
    "    \n",
    "    total_successful = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for config_item in event_configs:\n",
    "        print(f\"\\nüéØ Processing {config_item['description']}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        successful = extractor.batch_extract_nuclei_parallel(\n",
    "            max_samples=config_item['max_samples'],\n",
    "            event_types=config_item['types'],\n",
    "            dataset_name=DATASET_NAME\n",
    "        )\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        total_successful += successful\n",
    "        total_time += processing_time\n",
    "        \n",
    "        print(f\"   ‚úÖ Completed: {successful}/{config_item['max_samples']} nuclei\")\n",
    "        print(f\"   ‚è±Ô∏è  Time: {processing_time:.2f} seconds\")\n",
    "        print(f\"   üöÄ Rate: {successful/processing_time:.2f} nuclei/second\")\n",
    "    \n",
    "    print(f\"\\nüéâ Complete Extraction Summary:\")\n",
    "    print(f\"   ‚Ä¢ Total successful: {total_successful}\")\n",
    "    print(f\"   ‚Ä¢ Total time: {total_time/60:.2f} minutes\")\n",
    "    print(f\"   ‚Ä¢ Overall rate: {total_successful/total_time:.2f} nuclei/second\")\n",
    "    \n",
    "    # Final memory check\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    print(f\"   ‚Ä¢ Final memory usage: {memory_info.percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55116c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Analysis and Optimization Tips\n",
    "\n",
    "print(f\"üîß Performance Optimization Guide:\")\n",
    "print(f\"\\nüìä Current Configuration Analysis:\")\n",
    "print(f\"   ‚Ä¢ CPU cores available: {cpu_count()}\")\n",
    "print(f\"   ‚Ä¢ Batch workers: {config.max_workers_batch}\")\n",
    "print(f\"   ‚Ä¢ Frame workers: {config.max_workers_frames}\")\n",
    "print(f\"   ‚Ä¢ I/O workers: {config.max_workers_io}\")\n",
    "print(f\"   ‚Ä¢ Chunk size: {config.chunk_size}\")\n",
    "\n",
    "print(f\"\\nüí° Optimization Tips:\")\n",
    "print(f\"   1. **Memory**: If you have more RAM, increase chunk_size for fewer disk writes\")\n",
    "print(f\"   2. **CPU**: If CPU usage is low, increase max_workers_batch\")\n",
    "print(f\"   3. **Storage**: If using SSD, increase max_workers_io for faster file operations\")\n",
    "print(f\"   4. **Network Storage**: If using network storage, decrease I/O workers to avoid saturation\")\n",
    "print(f\"   5. **Large Datasets**: Use save_intermediate_results=True to avoid memory buildup\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance Tuning Examples:\")\n",
    "print(f\"\"\"\n",
    "# For high-memory systems (32+ GB RAM):\n",
    "high_memory_config = ParallelConfig(\n",
    "    max_workers_batch=8,\n",
    "    chunk_size=200,\n",
    "    max_memory_gb=24.0\n",
    ")\n",
    "\n",
    "# For many-core systems (16+ cores):\n",
    "many_core_config = ParallelConfig(\n",
    "    max_workers_batch=12,\n",
    "    max_workers_frames=16,\n",
    "    max_workers_io=32\n",
    ")\n",
    "\n",
    "# For network storage systems:\n",
    "network_config = ParallelConfig(\n",
    "    max_workers_io=4,  # Reduce I/O workers\n",
    "    chunk_size=20,     # Smaller chunks\n",
    "    save_intermediate_results=True\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# System resource monitoring\n",
    "cpu_percent = psutil.cpu_percent(interval=1)\n",
    "memory_info = psutil.virtual_memory()\n",
    "disk_info = psutil.disk_usage('/')\n",
    "\n",
    "print(f\"\\nüñ•Ô∏è  Current System Status:\")\n",
    "print(f\"   ‚Ä¢ CPU usage: {cpu_percent:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Memory usage: {memory_info.percent:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Disk usage: {disk_info.percent:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Available memory: {memory_info.available / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Configuration Examples\n",
    "\n",
    "print(\"üî¨ Advanced Usage Examples:\\n\")\n",
    "\n",
    "# Example 1: Custom time windows\n",
    "print(\"1. Custom Time Windows:\")\n",
    "custom_time_config = ParallelConfig(\n",
    "    frame_offsets=[-2, -1, 0, 1, 2],  # 5-frame window\n",
    "    max_workers_batch=4,\n",
    "    max_workers_frames=10\n",
    ")\n",
    "print(\"   ‚Ä¢ 5-frame window: t-2, t-1, t, t+1, t+2\")\n",
    "print(\"   ‚Ä¢ Good for studying longer temporal dynamics\")\n",
    "\n",
    "# Example 2: Sparse sampling\n",
    "print(\"\\n2. Sparse Temporal Sampling:\")\n",
    "sparse_config = ParallelConfig(\n",
    "    frame_offsets=[-10, -5, 0, 5, 10],  # Sparse sampling\n",
    "    max_workers_batch=6,\n",
    "    max_workers_frames=8\n",
    ")\n",
    "print(\"   ‚Ä¢ Sparse sampling: t-10, t-5, t, t+5, t+10\")\n",
    "print(\"   ‚Ä¢ Good for long-term behavior analysis\")\n",
    "\n",
    "# Example 3: Single frame extraction (for 2D CNN)\n",
    "print(\"\\n3. Single Frame Extraction (2D CNN):\")\n",
    "single_frame_config = ParallelConfig(\n",
    "    frame_offsets=[0],  # Only event frame\n",
    "    max_workers_batch=12,\n",
    "    max_workers_frames=1\n",
    ")\n",
    "print(\"   ‚Ä¢ Single frame: t only\")\n",
    "print(\"   ‚Ä¢ Good for 2D CNN training\")\n",
    "\n",
    "# Example 4: Memory-constrained system\n",
    "print(\"\\n4. Memory-Constrained Configuration:\")\n",
    "low_memory_config = ParallelConfig(\n",
    "    max_workers_batch=2,\n",
    "    chunk_size=10,\n",
    "    max_memory_gb=4.0,\n",
    "    save_intermediate_results=True\n",
    ")\n",
    "print(\"   ‚Ä¢ Small batch sizes and chunks\")\n",
    "print(\"   ‚Ä¢ Immediate result saving\")\n",
    "\n",
    "print(\"\\nüéØ To use custom configuration:\")\n",
    "print(\"\"\"\n",
    "# Create extractor with custom config\n",
    "custom_extractor = ParallelNucleusExtractor(DATA_PATH, custom_time_config)\n",
    "custom_extractor.load_dataset(DATASET_NAME)\n",
    "\n",
    "# Run extraction with custom parameters\n",
    "results = custom_extractor.batch_extract_nuclei_parallel(\n",
    "    max_samples=50,\n",
    "    event_types=[\"death\"],\n",
    "    dataset_name=DATASET_NAME\n",
    ")\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
