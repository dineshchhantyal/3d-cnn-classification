{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8737ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "PROJECT_ROOT = Path(\"/mnt/home/dchhantyal/3d-cnn-classification\")\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1307e516-fa4e-44e1-99f9-9fc18a6017d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvRNN, Config, resize_volume, NucleusDataset, DataLoader, RandomAugmentation3D\n",
    "from predict import predict_single_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a786bcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Prediction Example ---\n",
      "‚úÖ Trained model loaded from: /mnt/home/dchhantyal/3d-cnn-classification/model/notebooks/final_model.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Running Prediction Example ---\")\n",
    "\n",
    "# Create Config instance to access attributes\n",
    "config = Config()\n",
    "\n",
    "# Look for model file in common locations\n",
    "possible_model_paths = [\n",
    "    \"nucleus_classifier_model.pth\",\n",
    "    \"model/nucleus_classifier_model.pth\",\n",
    "    str(PROJECT_ROOT / \"model/notebooks\" / \"final_model.pth\"),\n",
    "    str(PROJECT_ROOT / \"model\" / \"nucleus_classifier_model.pth\"),\n",
    "    str(PROJECT_ROOT / \"checkpoints\" / \"nucleus_classifier_model.pth\"),\n",
    "    str(PROJECT_ROOT / \"saved_models\" / \"nucleus_classifier_model.pth\"),\n",
    "]\n",
    "\n",
    "model_path = None\n",
    "for path in possible_model_paths:\n",
    "    if os.path.exists(path):\n",
    "        model_path = path\n",
    "        break\n",
    "\n",
    "if model_path is None:\n",
    "    print(\"‚ùå No trained model found!\")\n",
    "    print(\"\\nLooked for model file in:\")\n",
    "    for path in possible_model_paths:\n",
    "        print(f\"  - {path}\")\n",
    "    print(\"\\nüìù To train a model first, run:\")\n",
    "    print(\"  python model/train.py\")\n",
    "    print(\"\\nüìù Or place your trained model file in one of the above locations.\")\n",
    "    exit(1)\n",
    "\n",
    "# 1. Initialize a new model instance and load the saved weights\n",
    "try:\n",
    "    inference_model = ConvRNN(num_classes=config.num_classes).to(config.device)\n",
    "    inference_model.load_state_dict(\n",
    "        torch.load(model_path, map_location=config.device)\n",
    "    )\n",
    "    print(f\"‚úÖ Trained model loaded from: {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fcf0b1e-deb1-42ce-bafa-0f9d9baf393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Results:\n",
      "Predicted Class: new_daughter\n",
      "Confidence: 0.8866\n"
     ]
    }
   ],
   "source": [
    "# 2. Define the file paths for your new, unseen sample\n",
    "new_sample_files = [\n",
    "    str(\n",
    "        PROJECT_ROOT\n",
    "        / \"data\"\n",
    "        / \"nuclei_state_dataset\"\n",
    "        / \"mitotic\"\n",
    "        / \"221016FUCCINanogstack3_nucleus1_frame19_count9\"\n",
    "        / \"previous\"\n",
    "        / \"raw_original.tif\"\n",
    "    ),\n",
    "    str(\n",
    "        PROJECT_ROOT\n",
    "        / \"data\"\n",
    "        / \"nuclei_state_dataset\"\n",
    "        / \"mitotic\"\n",
    "        / \"221016FUCCINanogstack3_nucleus1_frame19_count9\"\n",
    "        / \"current\"\n",
    "        / \"raw_original.tif\"\n",
    "    ),\n",
    "    str(\n",
    "        PROJECT_ROOT\n",
    "        / \"data\"\n",
    "        /\"nuclei_state_dataset\"\n",
    "        / \"mitotic\"\n",
    "        / \"221016FUCCINanogstack3_nucleus1_frame19_count9\"\n",
    "        / \"next\"\n",
    "        / \"raw_original.tif\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Check if sample files exist\n",
    "missing_files = [f for f in new_sample_files if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    print(\"\\n‚ö†Ô∏è  Sample files not found:\")\n",
    "    for f in missing_files:\n",
    "        print(f\"  - {f}\")\n",
    "    print(\"\\nUsing dummy prediction instead...\")\n",
    "\n",
    "    # Create a dummy prediction for demonstration\n",
    "    print(f\"\\nDummy Prediction Results:\")\n",
    "    print(f\"Predicted Class: mitotic\")\n",
    "    print(f\"Confidence: 0.8547\")\n",
    "    exit(0)\n",
    "\n",
    "# 3. Run the prediction\n",
    "try:\n",
    "    predicted_label, confidence_score = predict_single_sample(\n",
    "        model=inference_model, file_paths=new_sample_files, device=config.device\n",
    "    )\n",
    "    print(f\"\\nPrediction Results:\")\n",
    "    print(f\"Predicted Class: {predicted_label}\")\n",
    "    print(f\"Confidence: {confidence_score:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error during prediction: {e}\")\n",
    "    print(\"\\nThis could be due to:\")\n",
    "    print(\"  - Incompatible model architecture\")\n",
    "    print(\"  - Corrupted model file\")\n",
    "    print(\"  - Invalid input data format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8182a-7f09-464e-b1d3-8e21aebf84bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ed2ef-f309-4492-95c2-893f1b07c9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956d037-9c4c-4bcb-bc69-89a476111f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-gpu",
   "language": "python",
   "name": "jupyter-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
