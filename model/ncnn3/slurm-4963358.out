The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) modules/2.3-20240529   2) openblas/single-0.3.26
🚀 Starting Run. All outputs will be saved to: training_outputs/20250708-172013
⚙️ Using device: cuda
Hyperparameters: {'input_depth': 64, 'input_height': 64, 'input_width': 64, 'num_classes': 4, 'learning_rate': 1e-05, 'batch_size': 32, 'num_epochs': 300, 'num_input_channels': 3, 'patience': 50, 'max_samples_per_class': 500, 'preserve_minority_classes': [0, 3], 'random_seed': 42, 'use_gpu_augmentation': True}

📊 Original class distribution:
  mitotic: 213 samples
  new_daughter: 433 samples
  stable: 20,919 samples
  death: 24 samples
  ✅ mitotic: Preserving all 213 samples (minority class)
  ✅ new_daughter: Keeping all 433 samples (under limit)
  📉 stable: Limited from 20,919 to 500 samples
  ✅ death: Preserving all 24 samples (minority class)

📊 Final balanced class distribution:
  mitotic: 213 samples (18.2%)
  new_daughter: 433 samples (37.0%)
  stable: 500 samples (42.7%)
  death: 24 samples (2.1%)

🎯 Total samples reduced from 21,589 to 1,170 (5.4% of original)

✅ Dataset ready with 1170 balanced samples.
Class distribution: [213 433 500  24]
Class weights: [ 1.37323944  0.67551963  0.585      12.1875    ]

Loading datasets...
🚀 Using GPU-accelerated augmentation (applied in training loop)

📊 Original class distribution:
  mitotic: 213 samples
  new_daughter: 433 samples
  stable: 20,919 samples
  death: 24 samples
  ✅ mitotic: Preserving all 213 samples (minority class)
  ✅ new_daughter: Keeping all 433 samples (under limit)
  📉 stable: Limited from 20,919 to 500 samples
  ✅ death: Preserving all 24 samples (minority class)

📊 Final balanced class distribution:
  mitotic: 213 samples (18.2%)
  new_daughter: 433 samples (37.0%)
  stable: 500 samples (42.7%)
  death: 24 samples (2.1%)

🎯 Total samples reduced from 21,589 to 1,170 (5.4% of original)

✅ Dataset ready with 1170 balanced samples.

📊 Original class distribution:
  mitotic: 213 samples
  new_daughter: 433 samples
  stable: 20,919 samples
  death: 24 samples
  ✅ mitotic: Preserving all 213 samples (minority class)
  ✅ new_daughter: Keeping all 433 samples (under limit)
  📉 stable: Limited from 20,919 to 500 samples
  ✅ death: Preserving all 24 samples (minority class)

📊 Final balanced class distribution:
  mitotic: 213 samples (18.2%)
  new_daughter: 433 samples (37.0%)
  stable: 500 samples (42.7%)
  death: 24 samples (2.1%)

🎯 Total samples reduced from 21,589 to 1,170 (5.4% of original)

✅ Dataset ready with 1170 balanced samples.

Training on 936 samples, validating on 234 samples.
Model has 71,012 trainable parameters.

--- Starting Training ---
Epoch [001/300] | Duration: 200.66s | Train Loss: 1.3932 | Train Acc: 0.2553 | Val Loss: 1.3840 | Val Acc: 0.0769 | Val F1: 0.0649
🎉 New best model found! F1-Score: 0.0649. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [002/300] | Duration: 97.33s | Train Loss: 1.3642 | Train Acc: 0.3301 | Val Loss: 1.3535 | Val Acc: 0.2222 | Val F1: 0.1648
🎉 New best model found! F1-Score: 0.1648. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [003/300] | Duration: 100.70s | Train Loss: 1.3415 | Train Acc: 0.3889 | Val Loss: 1.3312 | Val Acc: 0.4060 | Val F1: 0.3463
🎉 New best model found! F1-Score: 0.3463. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [004/300] | Duration: 98.25s | Train Loss: 1.3138 | Train Acc: 0.4562 | Val Loss: 1.3239 | Val Acc: 0.4615 | Val F1: 0.3959
🎉 New best model found! F1-Score: 0.3959. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [005/300] | Duration: 99.18s | Train Loss: 1.3014 | Train Acc: 0.4829 | Val Loss: 1.3096 | Val Acc: 0.5043 | Val F1: 0.4213
🎉 New best model found! F1-Score: 0.4213. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [006/300] | Duration: 102.64s | Train Loss: 1.2945 | Train Acc: 0.4925 | Val Loss: 1.2923 | Val Acc: 0.5085 | Val F1: 0.4290
🎉 New best model found! F1-Score: 0.4290. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [007/300] | Duration: 104.90s | Train Loss: 1.2734 | Train Acc: 0.4872 | Val Loss: 1.2799 | Val Acc: 0.5128 | Val F1: 0.4337
🎉 New best model found! F1-Score: 0.4337. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [008/300] | Duration: 104.63s | Train Loss: 1.2670 | Train Acc: 0.5139 | Val Loss: 1.2772 | Val Acc: 0.5385 | Val F1: 0.4248
Epoch [009/300] | Duration: 99.87s | Train Loss: 1.2590 | Train Acc: 0.5342 | Val Loss: 1.2695 | Val Acc: 0.5342 | Val F1: 0.4380
🎉 New best model found! F1-Score: 0.4380. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [010/300] | Duration: 102.72s | Train Loss: 1.2399 | Train Acc: 0.5684 | Val Loss: 1.2563 | Val Acc: 0.5769 | Val F1: 0.4640
🎉 New best model found! F1-Score: 0.4640. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [011/300] | Duration: 101.69s | Train Loss: 1.2258 | Train Acc: 0.5684 | Val Loss: 1.2526 | Val Acc: 0.5684 | Val F1: 0.4598
Epoch [012/300] | Duration: 100.45s | Train Loss: 1.2240 | Train Acc: 0.5759 | Val Loss: 1.2604 | Val Acc: 0.5598 | Val F1: 0.4523
Epoch [013/300] | Duration: 97.44s | Train Loss: 1.2077 | Train Acc: 0.5887 | Val Loss: 1.2419 | Val Acc: 0.5897 | Val F1: 0.4745
🎉 New best model found! F1-Score: 0.4745. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [014/300] | Duration: 97.50s | Train Loss: 1.2043 | Train Acc: 0.5780 | Val Loss: 1.2326 | Val Acc: 0.5983 | Val F1: 0.4791
🎉 New best model found! F1-Score: 0.4791. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [015/300] | Duration: 96.90s | Train Loss: 1.1947 | Train Acc: 0.6143 | Val Loss: 1.2325 | Val Acc: 0.5983 | Val F1: 0.4776
Epoch [016/300] | Duration: 96.94s | Train Loss: 1.1702 | Train Acc: 0.6122 | Val Loss: 1.2195 | Val Acc: 0.5983 | Val F1: 0.4782
Epoch [017/300] | Duration: 98.13s | Train Loss: 1.1808 | Train Acc: 0.6026 | Val Loss: 1.2071 | Val Acc: 0.5983 | Val F1: 0.4758
Epoch [018/300] | Duration: 95.41s | Train Loss: 1.1554 | Train Acc: 0.6004 | Val Loss: 1.2073 | Val Acc: 0.6026 | Val F1: 0.4810
🎉 New best model found! F1-Score: 0.4810. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [019/300] | Duration: 93.38s | Train Loss: 1.1442 | Train Acc: 0.6111 | Val Loss: 1.2077 | Val Acc: 0.5983 | Val F1: 0.4786
Epoch [020/300] | Duration: 92.84s | Train Loss: 1.1287 | Train Acc: 0.6154 | Val Loss: 1.1948 | Val Acc: 0.6026 | Val F1: 0.4822
🎉 New best model found! F1-Score: 0.4822. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [021/300] | Duration: 97.15s | Train Loss: 1.1376 | Train Acc: 0.6165 | Val Loss: 1.2011 | Val Acc: 0.6154 | Val F1: 0.4932
🎉 New best model found! F1-Score: 0.4932. Saved to training_outputs/20250708-172013/best_model.pth
Epoch [022/300] | Duration: 94.00s | Train Loss: 1.1129 | Train Acc: 0.6261 | Val Loss: 1.1885 | Val Acc: 0.5940 | Val F1: 0.4778
Epoch [023/300] | Duration: 97.88s | Train Loss: 1.1226 | Train Acc: 0.6197 | Val Loss: 1.1793 | Val Acc: 0.6026 | Val F1: 0.4815
Epoch [024/300] | Duration: 93.52s | Train Loss: 1.1047 | Train Acc: 0.6357 | Val Loss: 1.1791 | Val Acc: 0.5983 | Val F1: 0.4756
Epoch [025/300] | Duration: 97.63s | Train Loss: 1.0942 | Train Acc: 0.6100 | Val Loss: 1.1825 | Val Acc: 0.5940 | Val F1: 0.4775
Epoch [026/300] | Duration: 97.08s | Train Loss: 1.1076 | Train Acc: 0.6100 | Val Loss: 1.1746 | Val Acc: 0.6026 | Val F1: 0.4820
Epoch [027/300] | Duration: 98.19s | Train Loss: 1.0872 | Train Acc: 0.6378 | Val Loss: 1.1688 | Val Acc: 0.6111 | Val F1: 0.4820
Epoch [028/300] | Duration: 97.37s | Train Loss: 1.0856 | Train Acc: 0.6378 | Val Loss: 1.1751 | Val Acc: 0.5983 | Val F1: 0.4644
Epoch [029/300] | Duration: 141.45s | Train Loss: 1.0867 | Train Acc: 0.6346 | Val Loss: 1.1701 | Val Acc: 0.5940 | Val F1: 0.4733
Epoch [030/300] | Duration: 192.38s | Train Loss: 1.0796 | Train Acc: 0.6410 | Val Loss: 1.1665 | Val Acc: 0.6068 | Val F1: 0.4872
Epoch [031/300] | Duration: 169.39s | Train Loss: 1.0530 | Train Acc: 0.6549 | Val Loss: 1.1673 | Val Acc: 0.5855 | Val F1: 0.4387
Epoch [032/300] | Duration: 103.42s | Train Loss: 1.0695 | Train Acc: 0.6453 | Val Loss: 1.1643 | Val Acc: 0.5983 | Val F1: 0.4673
Epoch [033/300] | Duration: 104.72s | Train Loss: 1.0472 | Train Acc: 0.6368 | Val Loss: 1.1686 | Val Acc: 0.5897 | Val F1: 0.4470
Epoch [034/300] | Duration: 107.29s | Train Loss: 1.0487 | Train Acc: 0.6453 | Val Loss: 1.1644 | Val Acc: 0.6111 | Val F1: 0.4825
Epoch [035/300] | Duration: 107.66s | Train Loss: 1.0215 | Train Acc: 0.6581 | Val Loss: 1.1601 | Val Acc: 0.6068 | Val F1: 0.4503
Epoch [036/300] | Duration: 105.54s | Train Loss: 1.0527 | Train Acc: 0.6400 | Val Loss: 1.1742 | Val Acc: 0.6068 | Val F1: 0.4739
Epoch [037/300] | Duration: 106.28s | Train Loss: 1.0356 | Train Acc: 0.6453 | Val Loss: 1.1743 | Val Acc: 0.5983 | Val F1: 0.4429
Epoch [038/300] | Duration: 106.02s | Train Loss: 1.0382 | Train Acc: 0.6592 | Val Loss: 1.1594 | Val Acc: 0.6026 | Val F1: 0.4493
Epoch [039/300] | Duration: 107.06s | Train Loss: 1.0363 | Train Acc: 0.6656 | Val Loss: 1.1592 | Val Acc: 0.6026 | Val F1: 0.4686
Epoch [040/300] | Duration: 105.66s | Train Loss: 1.0266 | Train Acc: 0.6677 | Val Loss: 1.1475 | Val Acc: 0.6111 | Val F1: 0.4746
Epoch [041/300] | Duration: 105.91s | Train Loss: 1.0205 | Train Acc: 0.6538 | Val Loss: 1.1507 | Val Acc: 0.6111 | Val F1: 0.4688
Epoch [042/300] | Duration: 105.97s | Train Loss: 1.0099 | Train Acc: 0.6613 | Val Loss: 1.1499 | Val Acc: 0.6111 | Val F1: 0.4721
Epoch [043/300] | Duration: 105.75s | Train Loss: 1.0145 | Train Acc: 0.6699 | Val Loss: 1.1446 | Val Acc: 0.6068 | Val F1: 0.4858
Epoch [044/300] | Duration: 104.71s | Train Loss: 0.9980 | Train Acc: 0.6688 | Val Loss: 1.1655 | Val Acc: 0.5983 | Val F1: 0.4403
Epoch [045/300] | Duration: 105.50s | Train Loss: 0.9938 | Train Acc: 0.6838 | Val Loss: 1.1559 | Val Acc: 0.6154 | Val F1: 0.4777
Epoch [046/300] | Duration: 106.49s | Train Loss: 0.9921 | Train Acc: 0.6816 | Val Loss: 1.1698 | Val Acc: 0.5897 | Val F1: 0.4310
Epoch [047/300] | Duration: 105.41s | Train Loss: 0.9781 | Train Acc: 0.6795 | Val Loss: 1.1501 | Val Acc: 0.6111 | Val F1: 0.4687
Epoch [048/300] | Duration: 104.40s | Train Loss: 0.9785 | Train Acc: 0.6752 | Val Loss: 1.1515 | Val Acc: 0.6068 | Val F1: 0.4455
Epoch [049/300] | Duration: 104.35s | Train Loss: 0.9789 | Train Acc: 0.6827 | Val Loss: 1.1719 | Val Acc: 0.6282 | Val F1: 0.4886
Epoch [050/300] | Duration: 104.07s | Train Loss: 0.9627 | Train Acc: 0.6784 | Val Loss: 1.1655 | Val Acc: 0.5940 | Val F1: 0.4330
Epoch [051/300] | Duration: 104.77s | Train Loss: 0.9687 | Train Acc: 0.6859 | Val Loss: 1.1523 | Val Acc: 0.6068 | Val F1: 0.4664
Epoch [052/300] | Duration: 103.33s | Train Loss: 0.9903 | Train Acc: 0.6517 | Val Loss: 1.1726 | Val Acc: 0.6026 | Val F1: 0.4399
Epoch [053/300] | Duration: 104.46s | Train Loss: 1.0007 | Train Acc: 0.6720 | Val Loss: 1.1534 | Val Acc: 0.6068 | Val F1: 0.4643
Epoch [054/300] | Duration: 102.40s | Train Loss: 0.9673 | Train Acc: 0.6870 | Val Loss: 1.1603 | Val Acc: 0.5855 | Val F1: 0.4520
Epoch [055/300] | Duration: 103.18s | Train Loss: 0.9607 | Train Acc: 0.6902 | Val Loss: 1.1600 | Val Acc: 0.5897 | Val F1: 0.4552
Epoch [056/300] | Duration: 103.46s | Train Loss: 0.9669 | Train Acc: 0.6731 | Val Loss: 1.1623 | Val Acc: 0.6282 | Val F1: 0.4773
Epoch [057/300] | Duration: 102.88s | Train Loss: 0.9680 | Train Acc: 0.6731 | Val Loss: 1.1498 | Val Acc: 0.6197 | Val F1: 0.4812
Epoch [058/300] | Duration: 104.61s | Train Loss: 0.9492 | Train Acc: 0.6838 | Val Loss: 1.1589 | Val Acc: 0.6197 | Val F1: 0.4761
Epoch [059/300] | Duration: 104.04s | Train Loss: 0.9665 | Train Acc: 0.6752 | Val Loss: 1.1461 | Val Acc: 0.6026 | Val F1: 0.4627
Epoch [060/300] | Duration: 104.68s | Train Loss: 0.9320 | Train Acc: 0.6816 | Val Loss: 1.1632 | Val Acc: 0.6068 | Val F1: 0.4686
Epoch [061/300] | Duration: 103.71s | Train Loss: 0.9425 | Train Acc: 0.6912 | Val Loss: 1.1468 | Val Acc: 0.6111 | Val F1: 0.4358
Epoch [062/300] | Duration: 105.97s | Train Loss: 0.9438 | Train Acc: 0.6827 | Val Loss: 1.1665 | Val Acc: 0.6197 | Val F1: 0.4732
Epoch [063/300] | Duration: 103.55s | Train Loss: 0.9192 | Train Acc: 0.6859 | Val Loss: 1.1430 | Val Acc: 0.6197 | Val F1: 0.4775
Epoch [064/300] | Duration: 104.00s | Train Loss: 0.9488 | Train Acc: 0.6902 | Val Loss: 1.1576 | Val Acc: 0.6111 | Val F1: 0.4643
Epoch [065/300] | Duration: 103.60s | Train Loss: 0.9504 | Train Acc: 0.6880 | Val Loss: 1.1594 | Val Acc: 0.6026 | Val F1: 0.4816
Epoch [066/300] | Duration: 104.93s | Train Loss: 0.9380 | Train Acc: 0.6859 | Val Loss: 1.1713 | Val Acc: 0.5855 | Val F1: 0.4218
Epoch [067/300] | Duration: 105.33s | Train Loss: 0.9402 | Train Acc: 0.6795 | Val Loss: 1.1457 | Val Acc: 0.6026 | Val F1: 0.4637
Epoch [068/300] | Duration: 104.97s | Train Loss: 0.9543 | Train Acc: 0.6902 | Val Loss: 1.1692 | Val Acc: 0.6154 | Val F1: 0.4778
Epoch [069/300] | Duration: 103.32s | Train Loss: 0.9358 | Train Acc: 0.6763 | Val Loss: 1.1571 | Val Acc: 0.6111 | Val F1: 0.4743
Epoch [070/300] | Duration: 104.80s | Train Loss: 0.9324 | Train Acc: 0.6806 | Val Loss: 1.1641 | Val Acc: 0.6026 | Val F1: 0.4297
Epoch [071/300] | Duration: 104.28s | Train Loss: 0.9231 | Train Acc: 0.6976 | Val Loss: 1.1566 | Val Acc: 0.5983 | Val F1: 0.4333

⏹️  Early stopping triggered after 71 epochs (patience: 50)
   Best F1-Score: 0.4932

✅ Training finished.

💾 Saving final artifacts...
📈 Saved training metrics plot to training_outputs/20250708-172013/training_metrics.png
📊 Saved final confusion matrix to training_outputs/20250708-172013/final_confusion_matrix.png
📝 Saved final classification report to training_outputs/20250708-172013/final_classification_report.txt

✨ Run complete.
